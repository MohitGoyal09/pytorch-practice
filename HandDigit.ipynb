{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "16dxkNELpdOQ"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Sx2VCl3p0yG",
    "outputId": "4fd0d4c6-d952-47c1-8588-491b692eada3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 186MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 28.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 91.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5KtmE6m_p5ux"
   },
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NG8zeYUpqE3C",
    "outputId": "5d846cf2-4b81-4c6e-d046-ee48787f06ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCNXg7_cqIpY",
    "outputId": "99ea6c54-3cc9-4cc3-d8a5-24270ffe1a39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJk1wAg6qL7g",
    "outputId": "3d13a6c3-a338-4bae-a980-5b661383f79a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "834UNHOpqeBg",
    "outputId": "af30e309-b0a9-4af8-ae7a-35f13e6b59e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "37Btc9BOqrjq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True , num_workers=1)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCkIUAfaq0cp",
    "outputId": "ea0e7c15-6b12-4e58-9989-738f1db4c9f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7a8bb02c6260>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HSiwUrC2rEUm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32 , 5 , 1)\n",
    "        self.conv2 = nn.Conv2d(32,64 , 5 , 1)\n",
    "        self.conv2_dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(64*4*4 , 512)\n",
    "        self.fc2 = nn.Linear(512 , 10)\n",
    "    def forward(self , x):\n",
    "      x = F.relu(F.max_pool2d(self.conv1(x) , 2))\n",
    "      x = F.relu(F.max_pool2d(self.conv2_dropout(self.conv2(x)) , 2))\n",
    "      x = torch.flatten(x , 1)\n",
    "      x = F.relu(self.fc1(x))\n",
    "      x = F.dropout(x , training=self.training)\n",
    "      x = self.fc2(x)\n",
    "      return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpj9uUP3thCc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters() , lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx , (data , target) in enumerate(train_dataloader):\n",
    "    data , target = data.to(device) , target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = loss_fn(output , target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % 20 == 0:\n",
    "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_dataloader.dataset)} ({100. * batch_idx / len(train_dataloader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.inference_mode():\n",
    "    for data , target in test_dataloader:\n",
    "      data , target = data.to(device) , target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += loss_fn(output , target).item()\n",
    "      pred = output.argmax(dim=1 , keepdim=True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({100. * correct / len(test_dataloader.dataset):.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4DJDug-tlGU",
    "outputId": "056886c7-cda8-4ec0-c931-3da99ec3de0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-bf7d449f7152>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301492\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.094851\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.834525\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.678274\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.630203\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.580054\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.660994\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.621334\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.577582\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.571770\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.553281\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.530695\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.549547\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.503436\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.526267\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.580931\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.538683\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.529165\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.545196\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.542173\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.554519\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.554339\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.553444\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.527068\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.513803\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.466595\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.533335\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.541203\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.537845\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.537885\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.510926\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.517741\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.506060\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.538618\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.547480\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.542262\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.492122\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.511595\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.519536\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.499130\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.525905\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.543585\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.516836\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.520157\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.465692\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.514634\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.500694\n",
      "Test set: Average loss: 0.0234, Accuracy: 9693/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.506865\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.476942\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.495026\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.484308\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.496050\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.514004\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.476120\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.507344\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.491405\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.507340\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.467398\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.461197\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.518688\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.543123\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.513568\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.484078\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.524661\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.492235\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.532244\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.479878\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.488457\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.477741\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.507673\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.490256\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.514681\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.484736\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.498392\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.518383\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.512591\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.500614\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.495767\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.497866\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.480278\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.503208\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.524427\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.474571\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.508164\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.469114\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.518864\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.462787\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.523510\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.485585\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.480383\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.499670\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.477855\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.465885\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.479012\n",
      "Test set: Average loss: 0.0233, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.483775\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.461731\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.508639\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.518667\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.501560\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.496753\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.515775\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.488520\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.510461\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.461161\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.478717\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.532931\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.507595\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.504082\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.492589\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.478253\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.477983\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.508174\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.482624\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.504782\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.464421\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.499770\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.508024\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.493447\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.513647\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.511499\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.510202\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.462013\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.520644\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.530555\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.491225\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.515218\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.477512\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.493577\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.519518\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.493781\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.467657\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.494115\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.498305\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.477015\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.497193\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.472337\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.492072\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.477243\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.533107\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.479381\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.505528\n",
      "Test set: Average loss: 0.0232, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.461593\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.478694\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.515127\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.496156\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.497329\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.491766\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.495005\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.477077\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.486418\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.462931\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.477524\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 1.495232\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.481063\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.499903\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.488514\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.472457\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.476864\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.461153\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.536696\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.514660\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.498879\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.510214\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.465018\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.484708\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.485249\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.487173\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 1.476586\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.496939\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.533287\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.505139\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.498761\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.485260\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.474626\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 1.492748\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 1.477682\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.489903\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.477371\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.470301\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 1.501886\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.497194\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.461179\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 1.507289\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.480331\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.490870\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.485939\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.477089\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 1.526918\n",
      "Test set: Average loss: 0.0231, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.507217\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.468296\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.476938\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 1.475576\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.474998\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.508126\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.490762\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 1.486135\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.511318\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.476830\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.476456\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 1.461339\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.473636\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.532258\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.497322\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.489846\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.478599\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 1.492352\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.476776\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 1.492039\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.476861\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.520535\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.493287\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 1.523412\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 1.489703\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.490262\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 1.477337\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.492416\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 1.474166\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.462039\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.522388\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 1.492289\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 1.515349\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 1.496104\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 1.471258\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.493574\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.507563\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.486165\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 1.476718\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.467554\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.492688\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 1.492090\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.513426\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 1.506981\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.490511\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.475437\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 1.483059\n",
      "Test set: Average loss: 0.0232, Accuracy: 9837/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.478298\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 1.498652\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 1.477337\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 1.477396\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 1.492377\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.483814\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 1.461873\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 1.466755\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 1.482229\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.461165\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.510141\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 1.478984\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 1.507502\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.490294\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 1.477456\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.478734\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 1.507703\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 1.461191\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 1.485839\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 1.461188\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.476789\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 1.476076\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 1.491776\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 1.497901\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 1.491671\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.496835\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 1.476487\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 1.482141\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 1.478137\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 1.478963\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.492934\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 1.476140\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 1.490774\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 1.507360\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 1.485821\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.468344\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 1.461165\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 1.476779\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 1.476040\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 1.476775\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.546647\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 1.491582\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 1.461158\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 1.482935\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 1.485131\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.461150\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 1.492440\n",
      "Test set: Average loss: 0.0232, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.485544\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 1.488642\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 1.477414\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 1.475929\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 1.461150\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.512967\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 1.492413\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 1.476777\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 1.477045\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 1.483236\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.481380\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 1.472614\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 1.476756\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 1.461151\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 1.492415\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.479710\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 1.506161\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 1.476775\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 1.531732\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 1.461296\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.461151\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 1.476406\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 1.493346\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 1.474072\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 1.492419\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.508021\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 1.482663\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 1.496168\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 1.461354\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 1.499843\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.475397\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 1.469041\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 1.507901\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 1.476791\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 1.489950\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.476539\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 1.461159\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 1.493718\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 1.461152\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 1.532483\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.490529\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 1.497921\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 1.498740\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 1.478187\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 1.492193\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.491787\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 1.475948\n",
      "Test set: Average loss: 0.0231, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.507269\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 1.490257\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 1.474467\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 1.461180\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 1.478691\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.485082\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 1.476785\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 1.492234\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 1.523830\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 1.461151\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.461150\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 1.490422\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 1.492433\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 1.515166\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 1.463638\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.492789\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 1.463283\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 1.496343\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 1.497393\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 1.476779\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.472802\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 1.476775\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 1.522348\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 1.520381\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 1.498862\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.461164\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 1.461167\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 1.476791\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 1.461150\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 1.491755\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.583433\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 1.494021\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 1.461419\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 1.482092\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 1.492400\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 1.492373\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 1.490890\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 1.496478\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 1.461151\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 1.491353\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.470047\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 1.476688\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 1.492341\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 1.461150\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 1.508018\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.461152\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 1.503644\n",
      "Test set: Average loss: 0.0232, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.492401\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 1.492402\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 1.498466\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 1.464324\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 1.476775\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 1.463655\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 1.477112\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 1.477340\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.486232\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 1.477798\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 1.462784\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 1.492400\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 1.481073\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 1.501781\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 1.476747\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 1.492392\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 1.476457\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 1.490010\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 1.461195\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 1.492406\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 1.491198\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 1.502337\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 1.461301\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 1.492400\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.468939\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 1.500732\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 1.488358\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 1.485341\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 1.505867\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 1.475785\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 1.461236\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 1.477168\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 1.493701\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.491560\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 1.492429\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 1.508010\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 1.482086\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 1.492506\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 1.461150\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 1.477850\n",
      "Test set: Average loss: 0.0232, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.523526\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 1.515829\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 1.492518\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 1.506176\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 1.492389\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 1.492400\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 1.476775\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 1.491824\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 1.520069\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 1.493771\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.492400\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 1.507307\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 1.477058\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 1.507818\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 1.499017\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.492493\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 1.461150\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 1.508014\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 1.461150\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 1.476776\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.461150\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 1.469421\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 1.488639\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 1.469836\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 1.476968\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.461164\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 1.492397\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 1.476775\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 1.461150\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 1.519354\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.492256\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 1.464456\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 1.476776\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 1.476770\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 1.492465\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.476775\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 1.492332\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 1.476987\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 1.536202\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 1.461150\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.483742\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 1.483154\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 1.476776\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 1.477082\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 1.461173\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.476792\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 1.502722\n",
      "Test set: Average loss: 0.0232, Accuracy: 9851/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "  train(epoch)\n",
    "  test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "pkcuorzQ1S98",
    "outputId": "2042a441-7b60-40fb-e7a1-ab795edf3dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction {prediction}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-bf7d449f7152>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Corrected the module name from 'mathplotlib' to 'matplotlib'\n",
    "model.eval()\n",
    "data , target = test_data[1]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "# Changed 'ouput' to 'output' to fix the typo\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim = 1 , keepdim = True)\n",
    "print('prediction {prediction}')\n",
    "# The issue is resolved by removing the first dimension using [0] before squeezing.\n",
    "# data.cpu().squeeze(0) has shape (1, 28, 28)\n",
    "# data.cpu()[0].squeeze(0) or data.cpu().squeeze(0)[0] will have shape (28, 28)\n",
    "plt.imshow(data.cpu()[0].squeeze(0) , cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaVbxJVC1mqG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "cell_execution_strategy": "setup",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
